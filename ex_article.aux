\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Sun2005}
\citation{Sun2006}
\citation{ref1}
\citation{riviere2000discontinuous}
\citation{CNM:CNM464}
\citation{ainsworth2007posteriori}
\citation{ainsworth2010fully}
\citation{ainsworth2009constant}
\citation{epshteyn2007estimation}
\citation{shahbazi2005explicit}
\citation{shahbazi2005explicit}
\citation{ainsworth2009constant}
\citation{ern2008posteriori}
\citation{ern2009discontinuous}
\citation{ainsworth2012note}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{biot1941general}
\citation{coussy2004poromechanics}
\citation{abou2013petroleum}
\citation{Du2007}
\newlabel{sec:main}{{2}{2}{Mathematical Model}{section.2}{}}
\newlabel{sec:main@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Mathematical Model}{2}{section.2}}
\newlabel{eq:mass_balance}{{2.1}{2}{Mathematical Model}{equation.3}{}}
\newlabel{eq:mass_balance@cref}{{[equation][1][2]2.1}{[1][2][]2}}
\newlabel{eq:kappa}{{2.2}{2}{Mathematical Model}{equation.4}{}}
\newlabel{eq:kappa@cref}{{[equation][2][2]2.2}{[1][2][]2}}
\newlabel{eq:wong_perm}{{2.3}{2}{Mathematical Model}{equation.5}{}}
\newlabel{eq:wong_perm@cref}{{[equation][3][2]2.3}{[1][2][]2}}
\newlabel{eq:volumetric_str}{{2.4}{2}{Mathematical Model}{equation.6}{}}
\newlabel{eq:volumetric_str@cref}{{[equation][4][2]2.4}{[1][2][]2}}
\citation{Jaeger2010}
\newlabel{eq:biot_coeff}{{2.11}{3}{Mathematical Model}{equation.11}{}}
\newlabel{eq:biot_coeff@cref}{{[equation][11][2]2.11}{[1][3][]3}}
\newlabel{eq:linear_balance}{{2.13}{3}{Mathematical Model}{equation.13}{}}
\newlabel{eq:linear_balance@cref}{{[section][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Numerical Discretizations}{3}{section.14}}
\citation{ErnA_StephansenA_ZuninoP-2009aa}
\citation{ern2008posteriori}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Pressure equation}{4}{subsection.20}}
\newlabel{eq:dgscheme}{{3.6}{4}{Pressure equation}{equation.21}{}}
\newlabel{eq:dgscheme@cref}{{[equation][6][3]3.6}{[1][4][]4}}
\citation{StenbergR-1998aa}
\citation{Dryja2003}
\citation{BurmanE_ZuninoP-2006aa}
\citation{Di-PietroD_ErnA_GuermondJ-2008aa}
\citation{HoustonP_SchwabC_SuliE-2002aa}
\citation{DawsonC_SunS_WheelerM-2004aa}
\citation{choo2018enriched}
\citation{Kadeethum2019}
\newlabel{stheta}{{3.7}{5}{Pressure equation}{equation.22}{}}
\newlabel{stheta@cref}{{[equation][7][3]3.7}{[1][4][]5}}
\newlabel{ftheta}{{3.8}{5}{Pressure equation}{equation.23}{}}
\newlabel{ftheta@cref}{{[equation][8][3]3.8}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Poroelasticity problem}{5}{subsection.25}}
\newlabel{eq:CG_U}{{3.10}{5}{Poroelasticity problem}{equation.26}{}}
\newlabel{eq:CG_U@cref}{{[equation][10][3]3.10}{[1][5][]5}}
\newlabel{eq:cgscheme}{{3.11}{5}{Poroelasticity problem}{equation.27}{}}
\newlabel{eq:cgscheme@cref}{{[equation][11][3]3.11}{[1][5][]5}}
\newlabel{Dtheta}{{3.12}{5}{Poroelasticity problem}{equation.28}{}}
\newlabel{Dtheta@cref}{{[equation][12][3]3.12}{[1][5][]5}}
\newlabel{sec:alg}{{4}{6}{Machine Learning Algorithm}{section.30}{}}
\newlabel{sec:alg@cref}{{[section][4][]4}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Machine Learning Algorithm}{6}{section.30}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces Build tree\relax }}{6}{algorithm.31}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:buildtree}{{4.1}{6}{Build tree\relax }{algorithm.31}{}}
\newlabel{alg:buildtree@cref}{{[algorithm][1][4]4.1}{[1][6][]6}}
\newlabel{sec:experiments}{{5}{6}{Numerical results}{section.40}{}}
\newlabel{sec:experiments@cref}{{[section][5][]5}{[1][6][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical results}{6}{section.40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Elliptic Problems}{6}{subsection.41}}
\newlabel{eq:mass_balance_elliptic}{{5.1}{6}{Elliptic Problems}{equation.42}{}}
\newlabel{eq:mass_balance_elliptic@cref}{{[equation][1][5]5.1}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}The effect of a polynomial degree approximation ($k$)}{6}{subsubsection.43}}
\newlabel{eq:darcy_exact_solution}{{5.2}{6}{The effect of a polynomial degree approximation ($k$)}{equation.63}{}}
\newlabel{eq:darcy_exact_solution@cref}{{[equation][2][5]5.2}{[1][6][]6}}
\newlabel{eq:darcy_exact_solution_kappa}{{5.3}{6}{The effect of a polynomial degree approximation ($k$)}{equation.64}{}}
\newlabel{eq:darcy_exact_solution_kappa@cref}{{[equation][3][5]5.3}{[1][6][]6}}
\newlabel{eq:darcy_source}{{5.4}{6}{The effect of a polynomial degree approximation ($k$)}{equation.65}{}}
\newlabel{eq:darcy_source@cref}{{[equation][4][5]5.4}{[1][6][]6}}
\citation{scikit-learn}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5.1}{\ignorespaces Investigation procedure for the elliptic problem\relax }}{7}{algorithm.44}}
\newlabel{alg:ell_effect_of_k}{{5.1}{7}{Investigation procedure for the elliptic problem\relax }{algorithm.44}{}}
\newlabel{alg:ell_effect_of_k@cref}{{[algorithm][1][5]5.1}{[1][6][]7}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The lowest $\beta $ value that provides the optimal error convergence rate solution with different $k$, discretization, and solver. Note that $\boldsymbol  {{\kappa }}$ is homogeneous.\relax }}{7}{table.caption.66}}
\newlabel{tab:ell_homo_beta_unstable}{{1}{7}{The lowest $\beta $ value that provides the optimal error convergence rate solution with different $k$, discretization, and solver. Note that $\boldsymbol {{\kappa }}$ is homogeneous.\relax }{table.caption.66}{}}
\newlabel{tab:ell_homo_beta_unstable@cref}{{[table][1][]1}{[1][6][]7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Number of linear iterative solver of SIPG for (\textbf  {a}) $k=1$, (\textbf  {b}) $k=2$, (\textbf  {c}) $k=3$, (\textbf  {d}) $k=4$, and (\textbf  {e}) $k=5$. Note that each line represents different value of ${\kappa }$, and the error bar shows mean and standard derivation of each number of iteration.\relax }}{8}{figure.caption.67}}
\newlabel{fig:ell_homo_sipg_noi}{{1}{8}{Number of linear iterative solver of SIPG for (\textbf {a}) $k=1$, (\textbf {b}) $k=2$, (\textbf {c}) $k=3$, (\textbf {d}) $k=4$, and (\textbf {e}) $k=5$. Note that each line represents different value of ${\kappa }$, and the error bar shows mean and standard derivation of each number of iteration.\relax }{figure.caption.67}{}}
\newlabel{fig:ell_homo_sipg_noi@cref}{{[figure][1][]1}{[1][7][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Number of linear iterative solver of IIPG for (\textbf  {a}) $k=1$, (\textbf  {b}) $k=2$, (\textbf  {c}) $k=3$, (\textbf  {d}) $k=4$, and (\textbf  {e}) $k=5$. Note that each line represents different value of ${\kappa }$, and the error bar shows mean and standard derivation of each number of iteration.\relax }}{9}{figure.caption.68}}
\newlabel{fig:ell_homo_iipg_noi}{{2}{9}{Number of linear iterative solver of IIPG for (\textbf {a}) $k=1$, (\textbf {b}) $k=2$, (\textbf {c}) $k=3$, (\textbf {d}) $k=4$, and (\textbf {e}) $k=5$. Note that each line represents different value of ${\kappa }$, and the error bar shows mean and standard derivation of each number of iteration.\relax }{figure.caption.68}{}}
\newlabel{fig:ell_homo_iipg_noi@cref}{{[figure][2][]2}{[1][7][]9}}
\citation{scikit-learn}
\citation{scikit-learn}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Elliptic equation with continuous exact solution: p-value results for each explanatory variable\relax }}{10}{table.caption.69}}
\newlabel{tab:linear_regression_p_value}{{2}{10}{Elliptic equation with continuous exact solution: p-value results for each explanatory variable\relax }{table.caption.69}{}}
\newlabel{tab:linear_regression_p_value@cref}{{[table][2][]2}{[1][10][]10}}
\@writefile{thm}{\contentsline {remark}{{Remark}{5.1}{}}{10}{theorem.70}}
\newlabel{eq:ell_regression_con}{{5.5}{10}{The effect of a polynomial degree approximation ($k$)}{equation.71}{}}
\newlabel{eq:ell_regression_con@cref}{{[equation][5][5]5.5}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}The effect of a type of exact solution and heterogeneous coefficient}{10}{subsubsection.74}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Neural network architecture used for the elliptic problem with continuous exact solution. The number of hidden layers, $N_{hl}$, and the number of neuron for each hidden layer, $N_n$, are used as the sensitivity analysis parameters.\relax }}{11}{figure.caption.72}}
\newlabel{fig:ell_ann_fig}{{3}{11}{Neural network architecture used for the elliptic problem with continuous exact solution. The number of hidden layers, $N_{hl}$, and the number of neuron for each hidden layer, $N_n$, are used as the sensitivity analysis parameters.\relax }{figure.caption.72}{}}
\newlabel{fig:ell_ann_fig@cref}{{[figure][3][]3}{[1][10][]11}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Elliptic equation with continuous exact solution: Mean squared error of the validation set for different number of hidden layers $N_{hl}$ and different number of neurons per layer $N_{n}$\relax }}{11}{table.caption.73}}
\newlabel{table:ell_hyper_nl_nn_con}{{3}{11}{Elliptic equation with continuous exact solution: Mean squared error of the validation set for different number of hidden layers $N_{hl}$ and different number of neurons per layer $N_{n}$\relax }{table.caption.73}{}}
\newlabel{table:ell_hyper_nl_nn_con@cref}{{[table][3][]3}{[1][10][]11}}
\newlabel{eq:darcy_exact_solution_1}{{5.6}{11}{The effect of a type of exact solution and heterogeneous coefficient}{equation.75}{}}
\newlabel{eq:darcy_exact_solution_1@cref}{{[equation][6][5]5.6}{[1][10][]11}}
\newlabel{eq:darcy_exact_solution_1_kappa}{{5.7}{11}{The effect of a type of exact solution and heterogeneous coefficient}{equation.76}{}}
\newlabel{eq:darcy_exact_solution_1_kappa@cref}{{[equation][7][5]5.7}{[1][11][]11}}
\newlabel{eq:darcy_source_1}{{5.8}{11}{The effect of a type of exact solution and heterogeneous coefficient}{equation.77}{}}
\newlabel{eq:darcy_source_1@cref}{{[equation][8][5]5.8}{[1][11][]11}}
\citation{scikit-learn}
\citation{scikit-learn}
\newlabel{eq:dis_exact_solution}{{5.9}{12}{The effect of a type of exact solution and heterogeneous coefficient}{equation.78}{}}
\newlabel{eq:dis_exact_solution@cref}{{[equation][9][5]5.9}{[1][11][]12}}
\newlabel{eq:darcy_exact_solution_dis_kappa}{{5.10}{12}{The effect of a type of exact solution and heterogeneous coefficient}{equation.79}{}}
\newlabel{eq:darcy_exact_solution_dis_kappa@cref}{{[equation][10][5]5.10}{[1][12][]12}}
\newlabel{eq:dis_bound_solution}{{5.11}{12}{The effect of a type of exact solution and heterogeneous coefficient}{equation.80}{}}
\newlabel{eq:dis_bound_solution@cref}{{[equation][11][5]5.11}{[1][12][]12}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The lowest $\beta $ value that provides the optimal convergence rate solution with different type of exact solution (continuous or discontinuous), $\theta $, and solver. Note that $\boldsymbol  {{\kappa }}$ is heterogeneous, and $k=1$.\relax }}{12}{table.caption.81}}
\newlabel{tab:ell_homo_beta_unstable_dis}{{4}{12}{The lowest $\beta $ value that provides the optimal convergence rate solution with different type of exact solution (continuous or discontinuous), $\theta $, and solver. Note that $\boldsymbol {{\kappa }}$ is heterogeneous, and $k=1$.\relax }{table.caption.81}{}}
\newlabel{tab:ell_homo_beta_unstable_dis@cref}{{[table][4][]4}{[1][12][]12}}
\newlabel{eq:ell_regression_dis}{{5.12}{12}{The effect of a type of exact solution and heterogeneous coefficient}{equation.84}{}}
\newlabel{eq:ell_regression_dis@cref}{{[equation][12][5]5.12}{[1][12][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Number of linear iterative solver of cases which $\boldsymbol  {{\kappa }}$ is heterogeneous and exact solution is continuous: (\textbf  {a}) SIPG, (\textbf  {b}) IIPG, $\boldsymbol  {{\kappa }}$ is heterogeneous and exact solution is discontinuous: (\textbf  {c}) SIPG, and (\textbf  {d}) IIPG. Note that each line represents different value of ${\kappa }$ for the continuous solution, and ${\kappa }_1$ and ${\kappa }_2$ for the discontinuous solution. The error bar shows mean and standard derivation of each number of iteration.\relax }}{13}{figure.caption.82}}
\newlabel{fig:ell_het_noi}{{4}{13}{Number of linear iterative solver of cases which $\boldsymbol {{\kappa }}$ is heterogeneous and exact solution is continuous: (\textbf {a}) SIPG, (\textbf {b}) IIPG, $\boldsymbol {{\kappa }}$ is heterogeneous and exact solution is discontinuous: (\textbf {c}) SIPG, and (\textbf {d}) IIPG. Note that each line represents different value of ${\kappa }$ for the continuous solution, and ${\kappa }_1$ and ${\kappa }_2$ for the discontinuous solution. The error bar shows mean and standard derivation of each number of iteration.\relax }{figure.caption.82}{}}
\newlabel{fig:ell_het_noi@cref}{{[figure][4][]4}{[1][12][]13}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Elliptic equation with discontinuous exact solution: p-value results for each explanatory variable\relax }}{13}{table.caption.83}}
\newlabel{tab:linear_regression_p_value_dis}{{5}{13}{Elliptic equation with discontinuous exact solution: p-value results for each explanatory variable\relax }{table.caption.83}{}}
\newlabel{tab:linear_regression_p_value_dis@cref}{{[table][5][]5}{[1][12][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Neural network architecture used for the elliptic problem with discontinuous exact solution. The number of hidden layers, $N_{hl}$, and the number of neuron for each hidden layer, $N_n$, are used as the sensitivity analysis parameters.\relax }}{14}{figure.caption.85}}
\newlabel{fig:ell_ann_fig_dis}{{5}{14}{Neural network architecture used for the elliptic problem with discontinuous exact solution. The number of hidden layers, $N_{hl}$, and the number of neuron for each hidden layer, $N_n$, are used as the sensitivity analysis parameters.\relax }{figure.caption.85}{}}
\newlabel{fig:ell_ann_fig_dis@cref}{{[figure][5][]5}{[1][14][]14}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Elliptic equation with discontinuous exact solution: Mean squared error of the validation set for different number of hidden layers $N_{hl}$ and different number of neurons per layer $N_{n}$\relax }}{14}{table.caption.86}}
\newlabel{table:ell_hyper_nl_nn_dis}{{6}{14}{Elliptic equation with discontinuous exact solution: Mean squared error of the validation set for different number of hidden layers $N_{hl}$ and different number of neurons per layer $N_{n}$\relax }{table.caption.86}{}}
\newlabel{table:ell_hyper_nl_nn_dis@cref}{{[table][6][]6}{[1][14][]14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Biot's equations}{14}{subsection.87}}
\newlabel{eq:biot_kappa}{{5.13}{14}{Biot's equations}{equation.88}{}}
\newlabel{eq:biot_kappa@cref}{{[equation][13][5]5.13}{[1][14][]14}}
\citation{scikit-learn}
\newlabel{eq:k_mult}{{5.14}{15}{Biot's equations}{equation.89}{}}
\newlabel{eq:k_mult@cref}{{[equation][14][5]5.14}{[1][14][]15}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5.2}{\ignorespaces Investigation procedure for the Biot's equations\relax }}{15}{algorithm.90}}
\newlabel{alg:biot_procedure}{{5.2}{15}{Investigation procedure for the Biot's equations\relax }{algorithm.90}{}}
\newlabel{alg:biot_procedure@cref}{{[algorithm][2][5]5.2}{[1][15][]15}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Biot's equations: p-value results for each explanatory variable\relax }}{15}{table.caption.115}}
\newlabel{tab:linear_regression_p_value_biot}{{7}{15}{Biot's equations: p-value results for each explanatory variable\relax }{table.caption.115}{}}
\newlabel{tab:linear_regression_p_value_biot@cref}{{[table][7][]7}{[1][15][]15}}
\newlabel{eq:biot_regression_dis}{{5.15}{16}{Biot's equations}{equation.116}{}}
\newlabel{eq:biot_regression_dis@cref}{{[equation][15][5]5.15}{[1][15][]16}}
\newlabel{eq:exact_solution}{{5.16}{16}{Biot's equations}{equation.117}{}}
\newlabel{eq:exact_solution@cref}{{[equation][16][5]5.16}{[1][16][]16}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Biot's equations: Confusion matrix of the logistic regression for the test set\relax }}{16}{table.caption.118}}
\newlabel{tab:biot_cm_logistic}{{8}{16}{Biot's equations: Confusion matrix of the logistic regression for the test set\relax }{table.caption.118}{}}
\newlabel{tab:biot_cm_logistic@cref}{{[table][8][]8}{[1][16][]16}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Biot's equations: Accuracy of the validation set for different number of hidden layers $N_{hl}$ and different number of neurons per layer $N_{n}$\relax }}{16}{table.caption.120}}
\newlabel{table:biot_hyper_nl_nn_dis}{{9}{16}{Biot's equations: Accuracy of the validation set for different number of hidden layers $N_{hl}$ and different number of neurons per layer $N_{n}$\relax }{table.caption.120}{}}
\newlabel{table:biot_hyper_nl_nn_dis@cref}{{[table][9][]9}{[1][16][]16}}
\bibstyle{siamplain}
\bibdata{lit}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Neural network architecture used for the Biot's equation. The number of hidden layers, $N_{hl}$, and the number of neuron for each hidden layer, $N_n$, are used as the sensitivity analysis parameters.\relax }}{17}{figure.caption.119}}
\newlabel{fig:biot_ann_fig}{{6}{17}{Neural network architecture used for the Biot's equation. The number of hidden layers, $N_{hl}$, and the number of neuron for each hidden layer, $N_n$, are used as the sensitivity analysis parameters.\relax }{figure.caption.119}{}}
\newlabel{fig:biot_ann_fig@cref}{{[figure][6][]6}{[1][16][]17}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Biot's equations: Confusion matrix of the artificial neural network (ANN) for the test set\relax }}{17}{table.caption.121}}
\newlabel{tab:biot_cm_ann}{{10}{17}{Biot's equations: Confusion matrix of the artificial neural network (ANN) for the test set\relax }{table.caption.121}{}}
\newlabel{tab:biot_cm_ann@cref}{{[table][10][]10}{[1][16][]17}}
\newlabel{sec:conclusions}{{6}{17}{Conclusions}{section.122}{}}
\newlabel{sec:conclusions@cref}{{[section][6][]6}{[1][16][]17}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{17}{section.122}}
